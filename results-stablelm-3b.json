{"results": {"truthfulqa_mc": {"mc1": 0.22399020807833536, "mc1_stderr": 0.014594964329474205, "mc2": 0.407484491602086, "mc2_stderr": 0.014606127634077301}}, "versions": {"truthfulqa_mc": 1}, "config": {"model": "stablelm-base-alpha-3b", "num_fewshot": 0, "batch_size": 4, "device": "cuda:0", "no_cache": true, "limit": null, "bootstrap_iters": 2, "description_dict": null}}